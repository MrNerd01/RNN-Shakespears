{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_3_part_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrNerd01/models/blob/master/Assignment_3_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rFUVgQq7CQx",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3 part  2 \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vkPjOSqCaV6",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing :\n",
        "* Download the Shakespear dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRIB94soC0UQ",
        "colab_type": "code",
        "outputId": "ecd88231-8e54-4fec-a3e9-997454f15d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-31 19:03:34--  https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘shakespeare.txt’\n",
            "\n",
            "shakespeare.txt     100%[===================>]   1.06M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2019-05-31 19:03:39 (113 MB/s) - ‘shakespeare.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBhAXCv9D4EW",
        "colab_type": "code",
        "outputId": "bc079723-c470-4b68-901d-0153280ce669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = open('./shakespeare.txt', 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgJaY71SEu53",
        "colab_type": "code",
        "outputId": "30bfa5ed-c590-4352-ac47-8de1fccd49be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:1000])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1TarmTYFqE-",
        "colab_type": "text"
      },
      "source": [
        "#  Data Prepocessing \n",
        "* As we can see in the above conversation there are lot of words and special characters which need to be removed such as the following :\n",
        "*  Recurrent words such as \"\" First Citizen , All\"\"\n",
        "* special characters such as \", \",\" : \",\" ;\" \n",
        "the above should be preocessed before the model is fitted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqAKOXPWFpB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEFI4hy2Ex2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f74d3c5d-4b10-413a-bd1f-2fce7321887a"
      },
      "source": [
        "corpus = text \n",
        "bannedWords = ['First', 'Citizen:','All',',',':','.']\n",
        "corpus = corpus.split()\n",
        "corpus = [ word for word in corpus if word not in bannedWords]\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "tokens = [w.translate(table) for w in corpus]\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "tokens = [word for word in tokens if word.isalpha()]\n",
        "\t# make lower case\n",
        "tokens = [word.lower() for word in tokens]\n",
        "\n",
        "print(tokens[:10])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', 'all', 'speak']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7CFnCWKUmdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_doc(lines, filename):\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmm2OxHXVRoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bB4TArHTZw7",
        "colab_type": "text"
      },
      "source": [
        "# Create Sequences with different Combinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbdYxgK1MJKw",
        "colab_type": "code",
        "outputId": "5bce396d-7806-4749-ef4a-e8a49019256e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "length = 50 + 1\n",
        "sequences = list()\n",
        "for i in range(length, len(tokens)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = tokens[i-length:i]\n",
        "\t# convert into a line\n",
        "\tline = ' '.join(seq)\n",
        "\t# store\n",
        "\tsequences.append(line)\n",
        "print('Sequences: %d' % len(sequences))\n",
        "#Save sequences for future use.\n",
        "save_doc(sequences,'sequences.txt')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequences: 202166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig7bFR6mNQK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding,Flatten,Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mDd96QeVYei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eb1800e3-fe1c-4868-ec27-75bc4e343b94"
      },
      "source": [
        "in_filename = 'sequences.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')[:10000]\n",
        "print(lines[:100])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['before we proceed any further hear me speak all speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own', 'we proceed any further hear me speak all speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price', 'proceed any further hear me speak all speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist', 'any further hear me speak all speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a', 'further hear me speak all speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict', 'hear me speak all speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all', 'me speak all speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no', 'speak all speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more', 'all speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking', 'speak speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont', 'speak you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let', 'you are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it', 'are all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be', 'all resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done', 'resolved rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away', 'rather to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away', 'to die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second', 'die than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one', 'than to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word', 'to famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good', 'famish all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens', 'all resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we', 'resolved resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are', 'resolved first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted', 'first you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor', 'you know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens', 'know caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the', 'caius marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians', 'marcius is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good', 'is chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what', 'chief enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority', 'enemy to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits', 'to the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on', 'the people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would', 'people all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve', 'all we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us', 'we knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if', 'knowt we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they', 'we knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would', 'knowt let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield', 'let us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us', 'us kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but', 'kill him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the', 'him and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity', 'and well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while', 'well have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it', 'have corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were', 'corn at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome', 'at our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we', 'our own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might', 'own price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess', 'price ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they', 'ist a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved', 'a verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us', 'verdict all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely', 'all no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but', 'no more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they', 'more talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think', 'talking ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we', 'ont let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are', 'let it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too', 'it be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear', 'be done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the', 'done away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness', 'away away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that', 'away second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts', 'second one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us', 'one word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the', 'word good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object', 'good citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of', 'citizens we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our', 'we are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery', 'are accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is', 'accounted poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as', 'poor citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an', 'citizens the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory', 'the patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to', 'patricians good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise', 'good what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their', 'what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance', 'authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our', 'surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance', 'on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is', 'would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a', 'relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain', 'us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to', 'if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them', 'they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let', 'would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us', 'yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge', 'us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this', 'but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with', 'the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with our', 'superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with our pikes', 'while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with our pikes ere', 'it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with our pikes ere we', 'were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with our pikes ere we become', 'wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with our pikes ere we become rakes', 'we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with our pikes ere we become rakes for', 'might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with our pikes ere we become rakes for the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2brndjs5M_qW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rheu0C5xN4fw",
        "colab_type": "code",
        "outputId": "757fbe82-9f37-43c2-e172-0722a7d2b369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUcY6F8xNlio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8jzP3z5XVrs",
        "colab_type": "text"
      },
      "source": [
        "# RNN using uni - directional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeaQpmLpNvwY",
        "colab_type": "code",
        "outputId": "16433d95-dec9-4aca-d96a-657ec2b75e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, batch_size=128, epochs=10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 50, 50)            111800    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2236)              225836    \n",
            "=================================================================\n",
            "Total params: 488,536\n",
            "Trainable params: 488,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 13s 1ms/step - loss: 6.8157 - acc: 0.0354\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 6.3601 - acc: 0.0418\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 6.3290 - acc: 0.0418\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 6.2619 - acc: 0.0418\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 6.1591 - acc: 0.0418\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 6.0569 - acc: 0.0434\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 5.9693 - acc: 0.0438\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 5.9109 - acc: 0.0469\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 5.8617 - acc: 0.0481\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 5.8186 - acc: 0.0512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f624e31ee80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyAo4lzVOJf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xanfbsHkWcSt",
        "colab_type": "text"
      },
      "source": [
        "# Prediction  for uni- directional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOq-nxBRWaQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "doc = load_doc('sequences.txt')\n",
        "lines = doc.split('\\n')\n",
        "seq_length = len(lines[0].split()) - 1\n",
        "model = load_model('model.h5')\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
        "seed_text = 'before'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWYsFeKCWvck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2df4f828-ff5b-4dbd-faed-352ebe2bbfa0"
      },
      "source": [
        "result = list()\n",
        "in_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "for _ in range(10):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "print(' '.join(result))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the people and the people and the people and the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9TyupwiaUF6",
        "colab_type": "text"
      },
      "source": [
        "# RNN using BiDirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zwf7Mh6X97z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "9be5a2b3-9278-4d5f-d1a8-0fd5f3744e66"
      },
      "source": [
        "from keras.layers import Activation, Dense,Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128, input_length=seq_length))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 50, 128)           286208    \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               12900     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2236)              225836    \n",
            "=================================================================\n",
            "Total params: 623,760\n",
            "Trainable params: 623,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPsRtqKYZJlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to file\n",
        "model.save('modelbi.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31TYDuvtZsTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "6b7c6967-82eb-48ce-9974-46023de2ac82"
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, batch_size=128, epochs=10)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 7.0750 - acc: 0.0380\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 6.4869 - acc: 0.0415\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 6.3240 - acc: 0.0418\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 6.2102 - acc: 0.0418\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 6.1372 - acc: 0.0418\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 6.0794 - acc: 0.0418\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 6.0092 - acc: 0.0418\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 5.9434 - acc: 0.0418\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 5.8803 - acc: 0.0418\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 5.8096 - acc: 0.0419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6226e47b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThFteeUWZvUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "32cc3b12-b3a2-46ad-e6b2-4e8141b1b673"
      },
      "source": [
        "doc = load_doc('sequences.txt')\n",
        "lines = doc.split('\\n')\n",
        "seq_length = len(lines[0].split()) - 1\n",
        "model = load_model('modelbi.h5')\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
        "seed_text = 'before'"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb1RNmfIabWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6251b86d-ec1b-42f7-cc00-1d80c0f8dfb6"
      },
      "source": [
        "result = list()\n",
        "in_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "for _ in range(10):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "print(' '.join(result))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "garners oaken oaken spoons spoons percussion spoons percussion countrymen renowned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoFWdKGVaiQS",
        "colab_type": "text"
      },
      "source": [
        "# Unidirectional LSTM only preserves information of the past because the only inputs it has seen are from the past.\n",
        "**OUTPUT of uni-directional LSTM** :-  \"the people and the people and the people and the\"\n",
        "\n",
        "# Using bidirectional will run your inputs in two ways, one from past to future and one from future to past \n",
        "**OUTPUT of BiDirectional LSTM** :-\"\" garners oaken oaken spoons spoons percussion spoons percussion countrymen renowned\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot5XJX-Xadyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}